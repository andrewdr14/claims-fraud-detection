<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Motor Insurance Fraud Detection</title>
    <link rel="stylesheet" href="{{ url_for('static', filename='styles.css') }}">
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #f4f4f4;
            margin: 20px;
            padding: 20px;
        }
        h1, h2 {
            color: #333;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            background-color: #fff;
            box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
        }
        th, td {
            padding: 10px;
            text-align: center;
            border-bottom: 1px solid #ddd;
        }
        th {
            background-color: #007bff;
            color: white;
        }
        footer {
            margin-top: 20px;
            text-align: center;
            font-size: 12px;
            color: #777;
        }
        .intro {
            padding: 15px;
            background-color: #ffffff;
            border: 1px solid #ddd;
            box-shadow: 0px 0px 5px rgba(0, 0, 0, 0.1);
        }
        .subsection {
            margin-bottom: 32px;
        }
        .graph-row {
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
            gap: 18px;
            margin: 18px 0 24px 0;
        }
        .inline-img {
            display: block;
            max-width: 33vw;
            min-width: 300px;
            width: 100%;
            height: 340px;
            object-fit: contain;
            border: 1px solid #ccc;
            background: #fff;
            padding: 5px;
            border-radius: 6px;
            margin: 0;
        }
        .feature-importance-img {
            display: block;
            width: 100%;
            min-width: 900px;
            max-width: 100vw;
            height: 420px;
            object-fit: contain;
            border: 1px solid #ccc;
            background: #fff;
            padding: 5px;
            border-radius: 6px;
            margin: 0 auto;
        }
        .metric-table {
            margin-bottom: 30px;
        }
        @media (max-width: 1000px) {
            .graph-row {
                flex-direction: column;
                gap: 10px;
            }
            .inline-img {
                max-width: 100%;
                min-width: 0;
                height: 260px;
            }
            .feature-importance-img {
                min-width: 0;
                width: 100%;
                height: 300px;
            }
        }
        .metric-details li {
            margin-bottom: 7px;
        }
    </style>
</head>
<body>
    <header>
        <h1>Motor Insurance Fraud Detection</h1>
    </header>

    <section class="intro">
        <h2>üîç Project Overview</h2>
        <p>This tool is designed to analyze insurance claims and detect potential fraud using machine learning models. It compares the performance of <strong>Random Forest</strong> and <strong>XGBoost</strong> classifiers in identifying fraudulent claims based on structured data.</p>
    </section>

    <section>
        <h2>üïµÔ∏è‚Äç‚ôÇÔ∏è How Fraudulent Claims Are Determined</h2>
        <div>
            <b>Fraud labels are assigned using a combination of strict business rules and limited randomness to better simulate a realistic, challenging fraud detection task:</b>
            <ul>
                <li>
                    <b>Rules:</b> A claim is marked as fraud if <u>two or more</u> of the following are true:
                    <ul>
                        <li><b>Total claim amount &gt; $17,500</b> <i>and</i> <b>deductible is $500</b></li>
                        <li><b>Incident time</b> is <b>before 4am or after 11pm</b></li>
                        <li><b>Insured is under 22 years old</b> <i>and</i> <b>claim amount &gt; $15,000</b></li>
                        <li><b>Number of vehicles &ge; 3</b> <i>and</i> <b>annual premium &gt; $3,000</b></li>
                        <li>Days since previous claim &lt; 180</li>
                        <li>Police report available is <b>No</b></li>
                    </ul>
                </li>
                <li>
                    <b>Randomness (Minimized):</b>
                    <ul>
                        <li>If only one rule is met, there‚Äôs a <b>very small</b> chance (&lt;1%) of being marked as fraud (to simulate rare mistakes).</li>
                        <li>If no rules are met, fraud is <b>almost never</b> assigned (&lt;0.1%).</li>
                        <li>Even if rules are met, a small number of fraudulent claims are missed to simulate occasional oversight.</li>
                    </ul>
                </li>
                <li>
                    <b>Explanation:</b> These rules ensure that only claims with multiple high-risk factors are marked as fraud, leading to a more realistic and challenging dataset for modeling.
                </li>
            </ul>
        </div>
    </section>

    <section>
        <h2>üìã Data Used</h2>
        <h3>All Data Points Generated and Used for Model Training</h3>
        <ul>
          {% for col in all_columns %}
            <li><b>{{ col }}</b>: {{ data_descriptions.get(col, "No description available.") }}</li>
          {% endfor %}
        </ul>
    </section>

    <section>
        <h2>üìä Policy Holder Statistics</h2>
        <table>
            <tr>
                <th>Statistic</th>
                <th>Value</th>
            </tr>
            <tr>
                <td>Total Policy Holders</td>
                <td>{{ summary_stats["Total Policy Holders"] }}</td>
            </tr>
            <tr>
                <td>Fraud Reported</td>
                <td>{{ summary_stats["Fraud Reported"] }}</td>
            </tr>
            <tr>
                <td>No Fraud Reported</td>
                <td>{{ summary_stats["No Fraud Reported"] }}</td>
            </tr>
        </table>
    </section>

    <section>
        <h2>üìà Statistical Analysis</h2>
        <table>
            <tr>
                <th>Feature</th>
                <th>Min</th>
                <th>Max</th>
                <th>Median</th>
                <th>Mean</th>
                <th>Std Dev</th>
            </tr>
            {% for feature in summary_stats.keys() if "Min" in feature %}
            <tr>
                <td>{{ feature.split(" - ")[0] }}</td>
                <td>{{ summary_stats[feature] }}</td>
                <td>{{ summary_stats[feature.replace("Min", "Max")] }}</td>
                <td>{{ summary_stats[feature.replace("Min", "Median")] }}</td>
                <td>{{ summary_stats[feature.replace("Min", "Mean")] }}</td>
                <td>{{ summary_stats[feature.replace("Min", "Std Dev")] }}</td>
            </tr>
            {% endfor %}
        </table>
    </section>

    <section>
        <h2>üõ°Ô∏è Random Forest Evaluation</h2>
        <table class="metric-table">
            <tr>
                <th>Metric</th>
                <th>Class 0 (No Fraud)</th>
                <th>Class 1 (Fraud)</th>
                <th>Macro Avg</th>
                <th>Weighted Avg</th>
            </tr>
            {% for metric in ["precision", "recall", "f1-score"] %}
            <tr>
                <td>{{ metric.capitalize() }}</td>
                <td>{{ "%.2f"|format(rf_results["0"][metric]) }}</td>
                <td>{{ "%.2f"|format(rf_results["1"][metric]) }}</td>
                <td>{{ "%.2f"|format(rf_results["macro avg"][metric]) }}</td>
                <td>{{ "%.2f"|format(rf_results["weighted avg"][metric]) }}</td>
            </tr>
            {% endfor %}
        </table>
        <p><b>ROC-AUC:</b> {{ "%.3f"|format(rf_roc_auc) }} &nbsp;|&nbsp; <b>PR-AUC:</b> {{ "%.3f"|format(rf_pr_auc) }}</p>
        <div class="graph-row">
            <img class="inline-img" src="data:image/png;base64,{{ rf_cm_img }}" alt="Random Forest Confusion Matrix" title="Random Forest Confusion Matrix">
            <img class="inline-img" src="data:image/png;base64,{{ rf_roc_img }}" alt="Random Forest ROC Curve" title="Random Forest ROC Curve">
            <img class="inline-img" src="data:image/png;base64,{{ rf_pr_img }}" alt="Random Forest Precision-Recall Curve" title="Random Forest Precision-Recall Curve">
        </div>
    </section>

    <section class="subsection">
        <h2>‚ö° XGBoost Evaluation</h2>
        <table class="metric-table">
            <tr>
                <th>Metric</th>
                <th>Class 0 (No Fraud)</th>
                <th>Class 1 (Fraud)</th>
                <th>Macro Avg</th>
                <th>Weighted Avg</th>
            </tr>
            {% for metric in ["precision", "recall", "f1-score"] %}
            <tr>
                <td>{{ metric.capitalize() }}</td>
                <td>{{ "%.2f"|format(xgb_results["0"][metric]) }}</td>
                <td>{{ "%.2f"|format(xgb_results["1"][metric]) }}</td>
                <td>{{ "%.2f"|format(xgb_results["macro avg"][metric]) }}</td>
                <td>{{ "%.2f"|format(xgb_results["weighted avg"][metric]) }}</td>
            </tr>
            {% endfor %}
        </table>
        <p><b>ROC-AUC:</b> {{ "%.3f"|format(xgb_roc_auc) }} &nbsp;|&nbsp; <b>PR-AUC:</b> {{ "%.3f"|format(xgb_pr_auc) }}</p>
        <div class="graph-row">
            <img class="inline-img" src="data:image/png;base64,{{ xgb_cm_img }}" alt="XGBoost Confusion Matrix" title="XGBoost Confusion Matrix">
            <img class="inline-img" src="data:image/png;base64,{{ xgb_roc_img }}" alt="XGBoost ROC Curve" title="XGBoost ROC Curve">
            <img class="inline-img" src="data:image/png;base64,{{ xgb_pr_img }}" alt="XGBoost Precision-Recall Curve" title="XGBoost Precision-Recall Curve">
        </div>
    </section>

    <section>
        <h2>üîç Feature Importance Comparison</h2>
        <div style="margin: 24px 0;">
            <img class="feature-importance-img" src="data:image/png;base64,{{ feature_importance_img }}" alt="Feature Importance Comparison" title="Feature Importance: Random Forest vs XGBoost">
        </div>
        <p>
            <i>
            This chart shows how important each model considers each feature for predicting insurance fraud.
            Higher bars mean greater influence on fraud prediction for that model.
            </i>
        </p>
    </section>

    <section>
        <h2>‚ÑπÔ∏è About The Evaluation Metrics</h2>
        <div style="background:#fff;padding:18px 20px 10px 20px;border:1px solid #ddd;border-radius:6px;margin-bottom:20px;">
            <ul class="metric-details">
                <li><b>Precision:</b> The proportion of positive identifications (claims predicted as fraud) that were actually correct. High precision means fewer false positives. <br>
                    <i>Example: If the model says 100 claims are fraud and 90 really are, precision is 0.90.</i>
                </li>
                <li><b>Recall (Sensitivity):</b> The proportion of actual positive cases (true fraud) that were identified correctly. High recall means fewer false negatives.<br>
                    <i>Example: If there are 100 actual fraud cases and the model finds 80, recall is 0.80.</i>
                </li>
                <li><b>F1-Score:</b> The harmonic mean of precision and recall. It is a single metric that balances both, especially useful if your data is imbalanced.<br>
                    <i>F1 = 2 √ó (precision √ó recall) / (precision + recall).</i>
                </li>
                <li><b>Confusion Matrix:</b> A table showing how many claims were correctly/incorrectly classified as fraud or not fraud. <br>
                    <i>Rows = Actual class, Columns = Predicted class. Top left = True Negatives, top right = False Positives, bottom left = False Negatives, bottom right = True Positives.</i>
                </li>
                <li><b>ROC-AUC (Receiver Operating Characteristic - Area Under Curve):</b> Measures the model's ability to distinguish between classes across all thresholds.<br>
                    <i>The ROC curve plots True Positive Rate vs. False Positive Rate. The AUC summarizes performance: 1.0 = perfect, 0.5 = random guessing. Higher is better.</i>
                </li>
                <li><b>PR-AUC (Precision-Recall Area Under Curve):</b> Especially useful for imbalanced data. Shows the tradeoff between precision and recall for different thresholds.<br>
                    <i>Higher PR-AUC means the model is better at finding actual fraud with fewer false alarms, even when fraud is rare.</i>
                </li>
            </ul>
        </div>
    </section>

    <section>
        <h2>üì• Download Dataset</h2>
        <p>You can download the processed dataset below:</p>
        <a href="{{ url_for('download_data') }}" class="btn">Download CSV</a>
    </section>

</body>
</html>